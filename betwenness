from multiprocessing import Pool
import itertools
import time

def chunks(nodeList, n):
    l_c = iter(nodeList)
    while True:
        x = tuple(itertools.islice(l_c, n))
        if not x:
            return
        yield x
        
def betweennessCentrality(Graph):
    return centrality_measure(*Graph)
    
def betweennessCentralityParallelSynchronous(graph, Process):
    p = Pool(processes = Process)
    nodeDivisor = len(p._pool)
    nodeChunks = list(chunks(graph.keys(), int(len(graph.keys())/nodeDivisor)))
    numChunks = len(nodeChunks)
    print("\nBegin\n")
    bt_sc = p.map(betweennessCentrality, zip([graph] * numChunks, nodeChunks))
    print("\nEnd\n")
    cb = {}
    for i in bt_sc:
    	for j in i.keys():
    		if j not in cb.keys():
    			cb[j] = i[j]
    		else:
    			cb[j] += i[j]
    return cb

def centrality_measure(graph, nodeList):
	queue, stack = [], []
	dist, pred, sigma, delta, cb = {}, {}, {}, {}, {}
	for i in graph.keys():
		dist[i], pred[i], sigma[i], delta[i], cb[i] = 0, [], 0, 0.0, 0.0
	for s in nodeList:
		for j in graph.keys():
			if pred[j]:
				del(pred[j])
			pred[j], dist[j], sigma[j], delta[j] = [], -1, 0, 0.0
		dist[s], sigma[s] = 0, 1
		queue.append(s)
		while queue:
			v = queue.pop(0)
			stack.append(v)
			for w in graph[v]:
				if dist[w] == -1:
					dist[w] = dist[v] + 1
					queue.append(w)
				if dist[w] == dist[v] + 1:
					sigma[w] += sigma[v]
					pred[w].append(v)
		while stack:
			w = stack.pop(-1)
			for v in pred[w]:
				delta[v] += (sigma[v] / sigma[w]) * (1 + delta[w])
			if w != s:
				cb[w] += delta[w]
	for i in cb.keys():
		cb[i] /= 2
	return cb
	
#paper referrence : 15326
#author : 12849

if __name__ == "__main__":
	filename1 = input("\nEnter graph file name : ")
	filename2 = input("\nEnter output file name : ")
	graph = {}
	with open(filename1, "r") as f:
		for i in iter(f):
			l = i.strip("\n").split(" ")
			if l[0] not in graph.keys():
				graph[l[0]] = [ l[i] for i in range(1, len(l)) ]
			else:
				for i in range(1, len(l)):
					graph[l[0]].append(l[i])
			del(l)
	print("\nFile read completed successfully")
	print("\nTotal number of vertices : ", len(graph.keys()), sep = "")
	start = time.time()
	cb = betweennessCentralityParallelSynchronous(graph, 4)
	end = time.time()
	with open(filename2, "w") as f:
		for i in cb.keys():
			f.writelines(str(i) + "\t" + str(cb[i]) + "\n")
	print("\nFile write completed successfully")
	print("\nTime spent in betweenness centrality computation : ", (end - start), " sec", sep = "")
